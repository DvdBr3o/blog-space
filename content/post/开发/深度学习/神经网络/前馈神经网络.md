---
title: 前馈神经网络
date: 2025-07-15T09:30:04+08:00
lastmod: 2025-07-16T18:07:47+08:00
tags:
  - 深度学习
  - 神经网络
categories: 深度学习
publish: true
---

```cardlink
url: https://www.bilibili.com/video/BV1pQ4y147re?vd_source=8f239ffdf35edff6291745a39aad66a2
title: "【深度学习 搞笑教程】18 前向传播 反向传播 | 草履虫都能听懂 零基础入门 | 持续更新_哔哩哔哩_bilibili"
description: "1 神经网络的种类2 前馈神经网络3 前向传播4 反向传播, 视频播放量 28116、弹幕量 139、点赞数 722、投硬币枚数 445、收藏人数 877、转发人数 187, 视频作者 编程八点档, 作者简介 学编程，有我在，别害怕。收看编程八点档，土鸡也能变凤凰。，相关视频：[5分钟深度学习] #01 梯度下降算法，【深度学习 搞笑教程】16 softmax回归 | 草履虫都能听懂 零基础入门 | 持续更新，[5分钟深度学习] #02 反向传播算法，60分钟Pytorch从入门到精通【第五期】！今天来讲【前向传播】！对零基础小白超友好的Pytorch教程~，5分钟-通俗易懂 - 神经网络 反向传播算法（手算），反向传播算法可视化展示，[5分钟深度学习] #03 激活函数，BP神经网络，【深度学习 搞笑教程】20 全连接神经网络的不足 | 草履虫都能听懂 零基础入门 | 持续更新，第八次-梯度下降法"
host: www.bilibili.com
image: https://i2.hdslb.com/bfs/archive/f08de3b231e828d8638c37ceb39904cf5ed356b2.jpg@100w_100h_1c.png
```

类似[线性神经网络](./%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md)，但更多层，也不局限于 加权函数$\to$激活函数 の 格式

## 传播

| 性质  | 前向传播          | 反向传播          |
| --- | ------------- | ------------- |
| 源对象 | 输入信号          | 损失梯度          |
| 终对象 | 输出信号          | 权重参数          |
| 方向  | 输入层 $\to$ 输出层 | 输出层 $\to$ 输入层 |

## 前向传播

将**输入信号**从输入层到输出层，层层级联地计算加权函数&激活函数

## 反向传播

aka. BP

将**损失梯度**从输出层到输入层，层层级联地更新权重参数

1. 列出[梯度下降法](./%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95.md)の总损失梯度迭代式 $$w_{k}^{(t+1)}=w_{k}^{(t)}-\lambda\cdot \left(\frac{ \partial E_{\mathrm{total}} }{ \partial w_{k} }\right)^{(t)} $$
2. 用链式法则求偏导 $$\frac{ \partial E_{\mathrm{total}} }{ \partial w_{k} } =\frac{ \partial E_{\mathrm{total}} }{ \partial \dots } \times\dots \times \frac{ \partial \dots }{ \partial w_{k} } $$
3. 逐个求部分偏导